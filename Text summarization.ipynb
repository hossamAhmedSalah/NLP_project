{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2734496,"sourceType":"datasetVersion","datasetId":1654566}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:27:24.934909Z","iopub.execute_input":"2024-04-27T14:27:24.935192Z","iopub.status.idle":"2024-04-27T14:27:38.597000Z","shell.execute_reply.started":"2024-04-27T14:27:24.935158Z","shell.execute_reply":"2024-04-27T14:27:38.595055Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom transformers import (AutoModelForSeq2SeqLM,\n                          AutoTokenizer,\n                          DataCollatorForSeq2Seq,\n                          TrainingArguments,\n                          Trainer,\n                          IntervalStrategy,\n                          EarlyStoppingCallback,\n                         )\nfrom datasets import Dataset, DatasetDict, load_metric\nimport torch\nimport nltk\nnltk.download(\"punkt\", quiet=True)\n\nmetric = load_metric(\"rouge\", trust_remote_code=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-27T14:59:40.266384Z","iopub.execute_input":"2024-04-27T14:59:40.267288Z","iopub.status.idle":"2024-04-27T14:59:40.488311Z","shell.execute_reply.started":"2024-04-27T14:59:40.267247Z","shell.execute_reply":"2024-04-27T14:59:40.487364Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nencoder_max_length = 512\ndecoder_max_length = 128\nbatch_size = 2","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:34:15.867476Z","iopub.execute_input":"2024-04-27T14:34:15.867900Z","iopub.status.idle":"2024-04-27T14:34:15.872791Z","shell.execute_reply.started":"2024-04-27T14:34:15.867869Z","shell.execute_reply":"2024-04-27T14:34:15.871695Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Data, Model, and Tokenizer","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv\")\ntrain_dataset = Dataset.from_pandas(train)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:27:47.768194Z","iopub.execute_input":"2024-04-27T14:27:47.768630Z","iopub.status.idle":"2024-04-27T14:27:48.889287Z","shell.execute_reply.started":"2024-04-27T14:27:47.768592Z","shell.execute_reply":"2024-04-27T14:27:48.888402Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"cheakPoint = \"facebook/bart-large-cnn\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(cheakPoint).to(device)\ntokenizer = AutoTokenizer.from_pretrained(cheakPoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:29:12.552642Z","iopub.execute_input":"2024-04-27T14:29:12.553577Z","iopub.status.idle":"2024-04-27T14:29:15.714432Z","shell.execute_reply.started":"2024-04-27T14:29:12.553533Z","shell.execute_reply":"2024-04-27T14:29:15.713549Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Working on a sample\ntrain_dataset = train_dataset.shuffle(seed=42)\ntrain, val = train_dataset.select(range(400)), train_dataset.select(range(400, 490))","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:29:37.189708Z","iopub.execute_input":"2024-04-27T14:29:37.190134Z","iopub.status.idle":"2024-04-27T14:29:37.221977Z","shell.execute_reply.started":"2024-04-27T14:29:37.190100Z","shell.execute_reply":"2024-04-27T14:29:37.219569Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"dataset_dict = DatasetDict({\"train\": train, \"validation\": val})\ndataset_dict.remove_columns(\"id\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:29:40.159157Z","iopub.execute_input":"2024-04-27T14:29:40.159551Z","iopub.status.idle":"2024-04-27T14:29:40.171482Z","shell.execute_reply.started":"2024-04-27T14:29:40.159520Z","shell.execute_reply":"2024-04-27T14:29:40.170358Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['article', 'highlights'],\n        num_rows: 400\n    })\n    validation: Dataset({\n        features: ['article', 'highlights'],\n        num_rows: 90\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tokenization Step","metadata":{}},{"cell_type":"code","source":"def batch_tokenize_preprocess(batch, tokenizer, encoder_max_length, decoder_max_length):\n    \n    source, target = batch[\"article\"], batch[\"highlights\"]\n    source_tokenized = tokenizer(source, padding=\"max_length\", truncation=True, max_length=encoder_max_length )\n    target_tokenized = tokenizer(target, padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n\n    # Ignore padding in the loss\n    target_labels = [\n        [-100 if token == tokenizer.pad_token_id else token for token in l]\n        for l in target_tokenized[\"input_ids\"]\n    ]\n\n    # Create a dictionary for the batch\n    batch_dict = {\n        \"input_ids\": source_tokenized[\"input_ids\"],\n        \"attention_mask\": source_tokenized[\"attention_mask\"],\n        \"labels\": target_labels,\n    }\n\n    return batch_dict","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:32:33.757049Z","iopub.execute_input":"2024-04-27T14:32:33.757734Z","iopub.status.idle":"2024-04-27T14:32:33.765695Z","shell.execute_reply.started":"2024-04-27T14:32:33.757698Z","shell.execute_reply":"2024-04-27T14:32:33.764486Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_data = train.map(\n    lambda batch: batch_tokenize_preprocess(batch, tokenizer, encoder_max_length, decoder_max_length),\n    batched=True,\n    remove_columns=train.column_names,\n)\n\nvalidation_data = val.map(\n    lambda batch: batch_tokenize_preprocess(batch, tokenizer, encoder_max_length, decoder_max_length),\n    batched=True,\n    remove_columns=val.column_names,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:34:21.454784Z","iopub.execute_input":"2024-04-27T14:34:21.455215Z","iopub.status.idle":"2024-04-27T14:34:22.528599Z","shell.execute_reply.started":"2024-04-27T14:34:21.455177Z","shell.execute_reply":"2024-04-27T14:34:22.527628Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c70b677b8554fd790941f363e2776b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/90 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36c1bf112d8a40508500cf756407425b"}},"metadata":{}}]},{"cell_type":"markdown","source":"# *Metric func* for compute metrics at evaluation. ","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n#     print(f\"preds: {preds}\")\n#     print(f\"labels: {labels}\")\n    decoded_preds = [tokenizer.batch_decode(np.argmax(pred, axis=1), skip_special_tokens=True) for pred in preds]\n    \n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = [tokenizer.batch_decode(label, skip_special_tokens=True) for label in labels]\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n\n    prediction_lens = [\n        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n    ]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {\n        k: round(v, 4) for k, v in result.items()\n    }\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:34:59.479632Z","iopub.execute_input":"2024-04-27T14:34:59.480077Z","iopub.status.idle":"2024-04-27T14:34:59.490369Z","shell.execute_reply.started":"2024-04-27T14:34:59.480046Z","shell.execute_reply":"2024-04-27T14:34:59.489249Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:34:59.972604Z","iopub.execute_input":"2024-04-27T14:34:59.973614Z","iopub.status.idle":"2024-04-27T14:34:59.978490Z","shell.execute_reply.started":"2024-04-27T14:34:59.973576Z","shell.execute_reply":"2024-04-27T14:34:59.977347Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Prepare the TrainingArguments module","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='bart_CNN_NLP',\n    num_train_epochs=4,  \n    per_device_train_batch_size=batch_size, \n    per_device_eval_batch_size=batch_size,\n    warmup_steps=500,\n    weight_decay=0.1,\n    label_smoothing_factor=0.1,\n    logging_dir=\"bart_logs\",\n    logging_steps=20,\n    load_best_model_at_end=True,\n    evaluation_strategy = \"steps\",\n    eval_steps = 40,\n    save_steps=1e6,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:38:41.689546Z","iopub.execute_input":"2024-04-27T14:38:41.689978Z","iopub.status.idle":"2024-04-27T14:38:41.730297Z","shell.execute_reply.started":"2024-04-27T14:38:41.689947Z","shell.execute_reply":"2024-04-27T14:38:41.729074Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_data,\n    eval_dataset=validation_data,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:38:43.935748Z","iopub.execute_input":"2024-04-27T14:38:43.936544Z","iopub.status.idle":"2024-04-27T14:38:43.964671Z","shell.execute_reply.started":"2024-04-27T14:38:43.936511Z","shell.execute_reply":"2024-04-27T14:38:43.963520Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Fine-Tuning step","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:38:45.885773Z","iopub.execute_input":"2024-04-27T14:38:45.886183Z","iopub.status.idle":"2024-04-27T14:47:44.285612Z","shell.execute_reply.started":"2024-04-27T14:38:45.886146Z","shell.execute_reply":"2024-04-27T14:47:44.284516Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [400/400 08:56, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>40</td>\n      <td>3.174800</td>\n      <td>3.156408</td>\n      <td>44.820800</td>\n      <td>26.673300</td>\n      <td>41.287300</td>\n      <td>41.226000</td>\n      <td>6433791.888900</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>3.064900</td>\n      <td>2.938647</td>\n      <td>45.846900</td>\n      <td>27.832700</td>\n      <td>41.854300</td>\n      <td>41.813900</td>\n      <td>6433791.855600</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>2.698300</td>\n      <td>2.871237</td>\n      <td>47.768100</td>\n      <td>29.856800</td>\n      <td>43.939600</td>\n      <td>43.881600</td>\n      <td>6433791.877800</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>2.672500</td>\n      <td>2.869803</td>\n      <td>46.643300</td>\n      <td>29.250400</td>\n      <td>43.129900</td>\n      <td>43.034800</td>\n      <td>6433791.933300</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.753700</td>\n      <td>2.853443</td>\n      <td>47.064500</td>\n      <td>29.623300</td>\n      <td>43.547900</td>\n      <td>43.484100</td>\n      <td>6433791.877800</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>2.372800</td>\n      <td>2.930520</td>\n      <td>46.167300</td>\n      <td>28.848000</td>\n      <td>42.629300</td>\n      <td>42.557700</td>\n      <td>6433791.888900</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>2.357200</td>\n      <td>2.941355</td>\n      <td>47.240800</td>\n      <td>29.420200</td>\n      <td>43.466800</td>\n      <td>43.374700</td>\n      <td>6433791.900000</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>2.087000</td>\n      <td>3.036608</td>\n      <td>46.652000</td>\n      <td>28.784400</td>\n      <td>42.764600</td>\n      <td>42.620400</td>\n      <td>6433791.877800</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>2.121200</td>\n      <td>3.016856</td>\n      <td>46.690200</td>\n      <td>28.199700</td>\n      <td>42.511400</td>\n      <td>42.422600</td>\n      <td>6433791.822200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>2.126400</td>\n      <td>3.047896</td>\n      <td>45.875100</td>\n      <td>28.191700</td>\n      <td>42.092200</td>\n      <td>41.993400</td>\n      <td>6433791.833300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=400, training_loss=2.5789558506011963, metrics={'train_runtime': 537.4812, 'train_samples_per_second': 2.977, 'train_steps_per_second': 0.744, 'total_flos': 1733683681689600.0, 'train_loss': 2.5789558506011963, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Generate sumary","metadata":{}},{"cell_type":"code","source":"def generate_summary(test_samples, model, max_length):\n    inputs = tokenizer(\n        test_samples,\n        padding=True,\n        truncation=True,\n        max_length=max_length,\n        return_tensors=\"pt\",\n    )\n    input_ids = inputs.input_ids.to(model.device)\n    attention_mask = inputs.attention_mask.to(model.device)\n    outputs = model.generate(input_ids, attention_mask=attention_mask)\n    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    return output_str","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:02:30.140794Z","iopub.execute_input":"2024-04-27T15:02:30.141658Z","iopub.status.idle":"2024-04-27T15:02:30.149508Z","shell.execute_reply.started":"2024-04-27T15:02:30.141611Z","shell.execute_reply":"2024-04-27T15:02:30.148498Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"sample = \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\"","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:11:24.798055Z","iopub.execute_input":"2024-04-27T15:11:24.798535Z","iopub.status.idle":"2024-04-27T15:11:24.805831Z","shell.execute_reply.started":"2024-04-27T15:11:24.798501Z","shell.execute_reply":"2024-04-27T15:11:24.804754Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"res = generate_summary(sample, trainer.model, max_length=1028)\nres","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:11:35.670507Z","iopub.execute_input":"2024-04-27T15:11:35.670950Z","iopub.status.idle":"2024-04-27T15:11:37.063929Z","shell.execute_reply.started":"2024-04-27T15:11:35.670916Z","shell.execute_reply":"2024-04-27T15:11:37.062976Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"['The Eiffel Tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris.\\nDuring its construction, the EIFFel Tower surpassed the Washington Monument to become the tallest man-made structure in the world.\\nIt held the title for 41 years until the Chrysler Building in New York City was finished in 1930.']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Push the model to my HuggingFace 🤗 repo","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:52:25.392166Z","iopub.execute_input":"2024-04-27T14:52:25.392566Z","iopub.status.idle":"2024-04-27T14:52:25.423333Z","shell.execute_reply.started":"2024-04-27T14:52:25.392525Z","shell.execute_reply":"2024-04-27T14:52:25.422628Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"325d11260cd8485d935169ebaf539259"}},"metadata":{}}]},{"cell_type":"code","source":"# Push your model to the Model Hub\ntrainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:15:34.442997Z","iopub.execute_input":"2024-04-27T15:15:34.443893Z","iopub.status.idle":"2024-04-27T15:16:18.730610Z","shell.execute_reply.started":"2024-04-27T15:15:34.443857Z","shell.execute_reply":"2024-04-27T15:16:18.729621Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1714223528.dac0803a1b2d.5846.6:   0%|          | 0.00/5.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb047687835d4e468c976f9df9ae4720"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1714214491.dac0803a1b2d.34.0:   0%|          | 0.00/11.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c43920fbe3264fe2abff78a5fecb7828"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b705e8cd4f345b3b6e3801f13501f95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1714223507.dac0803a1b2d.5846.5:   0%|          | 0.00/5.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bae7cdb7f79424285178e5825c83273"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 6 LFS files:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7e1497fc4d2407f92f2f6030fdc9654"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1714228525.dac0803a1b2d.7049.0:   0%|          | 0.00/7.33k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59b684fe1f6a4711bacdbd8bfbd029b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.86k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f77026be6f5e42fc99c00cfd9d2241a4"}},"metadata":{}},{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Moatasem22/bart_CNN_NLP/commit/31cf7b76fd7df65e3653a4fed631b6ed531d34b0', commit_message='End of training', commit_description='', oid='31cf7b76fd7df65e3653a4fed631b6ed531d34b0', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}